{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.utils.loader import *\n",
    "from scipy.sparse import *\n",
    "import numpy as np\n",
    "from src.utils.feature_weighting import *\n",
    "from src.utils.matrix_utils import compute_cosine, top_k_filtering\n",
    "from src.utils.BaseRecommender import BaseRecommender\n",
    "\n",
    "\n",
    "class ContentBasedFiltering(BaseRecommender):\n",
    "\n",
    "    \"\"\"\n",
    "    Good conf: tag aggr 3,10; tfidf l1 norm over all matrix\n",
    "    MAP@5  0.11772497678137457 with 10 shrinkage,\n",
    "                                    100 k_filtering and other as before\n",
    "    MAP@5  0.12039006297936491 urm weight 0.7\n",
    "    MAP@5  0.12109109578826009 without playcount and duration\n",
    "\n",
    "    Current best:\n",
    "    CBF (album 1.0, artists 1.0, no duration/playcount)\n",
    "        + URM 0.8\n",
    "        + TOP-55 (TFIDF (tags 1.0))\n",
    "        MAP@5 0.11897304011860126\n",
    "        Public leaderboard: 0.09616\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10, k_filtering=100):\n",
    "        # final matrix of predictions\n",
    "        self.R_hat = None\n",
    "\n",
    "        # for keeping reference between playlist and row index\n",
    "        self.pl_id_list = []\n",
    "        # for keeping reference between tracks and column index\n",
    "        self.tr_id_list = []\n",
    "\n",
    "        self.shrinkage = shrinkage\n",
    "        self.k_filtering = k_filtering\n",
    "\n",
    "    def fit(self, urm, target_playlist, target_tracks, dataset):\n",
    "        \"\"\"\n",
    "        urm: user rating matrix\n",
    "        target playlist is a list of playlist id\n",
    "        target_tracks is a list of track id\n",
    "        shrinkage: shrinkage factor for significance weighting\n",
    "        S = ICM' ICM\n",
    "        R = URM S\n",
    "        In between eliminate useless row of URM and useless cols of S\n",
    "        \"\"\"\n",
    "        # initialization\n",
    "\n",
    "        self.pl_id_list = list(target_playlist)\n",
    "        self.tr_id_list = list(target_tracks)\n",
    "        self.dataset = dataset\n",
    "        S = None\n",
    "        urm = urm.tocsr()\n",
    "        print(\"CBF started\")\n",
    "        # get ICM from dataset, assume it already cleaned\n",
    "        icm = dataset.build_icm_2()\n",
    "\n",
    "        # Build the tag matrix, apply TFIDF\n",
    "        print(\"Build tags matrix and apply TFIDF...\")\n",
    "        icm_tag = dataset.build_tags_matrix()\n",
    "        tags = applyTFIDF(icm_tag)\n",
    "\n",
    "        # Before stacking tags with the rest of the ICM, we keep only\n",
    "        # the top K tags for each item. This way we try to reduce the\n",
    "        # natural noise added by such sparse features.\n",
    "        tags = top_k_filtering(tags.transpose(), topK=55).transpose()\n",
    "\n",
    "        # stack all\n",
    "        icm = vstack([icm, tags, urm * 0.8], format='csr')\n",
    "\n",
    "        S = compute_cosine(icm.transpose()[[dataset.get_track_index_from_id(x)\n",
    "                                            for x in self.tr_id_list]],\n",
    "                           icm,\n",
    "                           k_filtering=self.k_filtering,\n",
    "                           shrinkage=self.shrinkage,\n",
    "                           n_threads=4,\n",
    "                           chunksize=300)\n",
    "        s_norm = S.sum(axis=1)\n",
    "\n",
    "        # Normalize S\n",
    "        S = S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "        print(\"Similarity matrix ready!\")\n",
    "\n",
    "        # Keep only the target playlists in the URM\n",
    "        urm_cleaned = urm[[dataset.get_playlist_index_from_id(x)\n",
    "                           for x in self.pl_id_list]]\n",
    "        self.S = S.transpose()\n",
    "\n",
    "        # Compute ratings\n",
    "        R_hat = urm_cleaned.dot(S.transpose().tocsc()).tocsr()\n",
    "        print(\"R_hat done\")\n",
    "\n",
    "        # Remove the entries in R_hat that are already present in the URM\n",
    "        urm_cleaned = urm_cleaned[:, [dataset.get_track_index_from_id(x)\n",
    "                                      for x in self.tr_id_list]]\n",
    "        R_hat[urm_cleaned.nonzero()] = 0\n",
    "        R_hat.eliminate_zeros()\n",
    "\n",
    "        print(\"Shape of final matrix: \", R_hat.shape)\n",
    "        self.R_hat = R_hat\n",
    "\n",
    "    def getW(self):\n",
    "        \"\"\"\n",
    "        Returns the similary matrix with dimensions I x I\n",
    "        S is IxT\n",
    "        \"\"\"\n",
    "        return self.S.tocsr()\n",
    "\n",
    "    def predict(self, at=5):\n",
    "        \"\"\"\n",
    "        returns a dictionary of\n",
    "        'pl_id': ['tr_1', 'tr_at'] for each playlist in target playlist\n",
    "        \"\"\"\n",
    "        recs = {}\n",
    "        for i in range(0, self.R_hat.shape[0]):\n",
    "            pl_id = self.pl_id_list[i]\n",
    "            pl_row = self.R_hat.data[self.R_hat.indptr[i]:\n",
    "                                     self.R_hat.indptr[i + 1]]\n",
    "            # get top 5 indeces. argsort, flip and get first at-1 items\n",
    "            sorted_row_idx = np.flip(pl_row.argsort(), axis=0)[0:at]\n",
    "            track_cols = [self.R_hat.indices[self.R_hat.indptr[i] + x]\n",
    "                          for x in sorted_row_idx]\n",
    "            tracks_ids = [self.tr_id_list[x] for x in track_cols]\n",
    "            recs[pl_id] = tracks_ids\n",
    "        return recs\n",
    "\n",
    "    def getR_hat(self):\n",
    "        return self.R_hat\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Returns the complete R_hat\n",
    "        \"\"\"\n",
    "        return self.R_hat.copy()\n",
    "\n",
    "\n",
    "def applyTFIDF(matrix):\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    transformer = TfidfTransformer(norm='l1', use_idf=True,\n",
    "                                   smooth_idf=True, sublinear_tf=False)\n",
    "    tfidf = transformer.fit_transform(matrix.transpose())\n",
    "    return tfidf.transpose()\n",
    "\n",
    "\n",
    "def produceCsv():\n",
    "    # export csv\n",
    "    dataset = Dataset(load_tags=True,\n",
    "                      filter_tag=False,\n",
    "                      weight_tag=False)\n",
    "    dataset.set_track_attr_weights_2(1.0, 1.0, 0.0, 0.0, 0.0,\n",
    "                                     1.0, 1.0, 0.0, 0.0)\n",
    "    cbf_exporter = ContentBasedFiltering()\n",
    "    urm = dataset.build_train_matrix()\n",
    "    tg_playlist = list(dataset.target_playlists.keys())\n",
    "    tg_tracks = list(dataset.target_tracks.keys())\n",
    "    # Train the model with the best shrinkage found in cross-validation\n",
    "    cbf_exporter.fit(urm,\n",
    "                     tg_playlist,\n",
    "                     tg_tracks,\n",
    "                     dataset)\n",
    "    recs = cbf_exporter.predict()\n",
    "    with open('submission_cbf.csv', mode='w', newline='') as out:\n",
    "        fieldnames = ['playlist_id', 'track_ids']\n",
    "        writer = csv.DictWriter(out, fieldnames=fieldnames, delimiter=',')\n",
    "        writer.writeheader()\n",
    "        for k in tg_playlist:\n",
    "            track_ids = ''\n",
    "            for r in recs[k]:\n",
    "                track_ids = track_ids + r + ' '\n",
    "            writer.writerow({'playlist_id': k,\n",
    "                             'track_ids': track_ids[:-1]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.utils.evaluator import Evaluator\n",
    "dataset = Dataset(load_tags=True,\n",
    "                  filter_tag=False,\n",
    "                  weight_tag=False)\n",
    "dataset.set_track_attr_weights_2(1.0, 1.0, 0.0, 0.0, 0.0,\n",
    "                                 1.0, 1.0, 0.0, 0.0)\n",
    "ev = Evaluator()\n",
    "ev.cross_validation(5, dataset.train_final.copy())\n",
    "cbf = ContentBasedFiltering()\n",
    "urm, tg_tracks, tg_playlist = ev.get_fold(dataset)\n",
    "cbf.fit(urm,\n",
    "        list(tg_playlist),\n",
    "        list(tg_tracks),\n",
    "        dataset)\n",
    "recs = cbf.predict()\n",
    "ev.evaluate_fold(recs)\n",
    "\n",
    "map_at_five = ev.get_mean_map()\n",
    "print(\"MAP@5 \", map_at_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
