{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.loader import *\n",
    "from scipy.sparse import *\n",
    "import numpy as np\n",
    "from src.utils.feature_weighting import *\n",
    "from src.utils.matrix_utils import compute_cosine, top_k_filtering, yadistance\n",
    "from src.utils.BaseRecommender import BaseRecommender\n",
    "\n",
    "\n",
    "class ContentBasedFiltering(BaseRecommender):\n",
    "\n",
    "    \"\"\"\n",
    "    Good conf: tag aggr 3,10; tfidf l1 norm over all matrix\n",
    "    MAP@5  0.11772497678137457 with 10 shrinkage,\n",
    "                                    100 k_filtering and other as before\n",
    "    MAP@5  0.12039006297936491 urm weight 0.7\n",
    "    MAP@5  0.12109109578826009 without playcount and duration\n",
    "\n",
    "    Current best:\n",
    "    CBF (album 1.0, artists 1.0, no duration/playcount)\n",
    "        + URM 0.8\n",
    "        + TOP-55 (TFIDF (tags 1.0))\n",
    "        MAP@5 0.11897304011860126\n",
    "        Public leaderboard: 0.09616\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10, k_filtering=100):\n",
    "        # final matrix of predictions\n",
    "        self.R_hat = None\n",
    "\n",
    "        # for keeping reference between playlist and row index\n",
    "        self.pl_id_list = []\n",
    "        # for keeping reference between tracks and column index\n",
    "        self.tr_id_list = []\n",
    "\n",
    "        self.shrinkage = shrinkage\n",
    "        self.k_filtering = k_filtering\n",
    "\n",
    "    def fit(self, urm, target_playlist, target_tracks, dataset, topK_tag=55):\n",
    "        \"\"\"\n",
    "        urm: user rating matrix\n",
    "        target playlist is a list of playlist id\n",
    "        target_tracks is a list of track id\n",
    "        shrinkage: shrinkage factor for significance weighting\n",
    "        S = ICM' ICM\n",
    "        R = URM S\n",
    "        In between eliminate useless row of URM and useless cols of S\n",
    "        \"\"\"\n",
    "        # initialization\n",
    "\n",
    "        self.pl_id_list = list(target_playlist)\n",
    "        self.tr_id_list = list(target_tracks)\n",
    "        self.dataset = dataset\n",
    "        S = None\n",
    "        urm = urm.tocsr()\n",
    "        print(\"CBF started\")\n",
    "        # get ICM from dataset, assume it already cleaned\n",
    "        icm = dataset.build_icm()\n",
    "\n",
    "        # Build the tag matrix, apply TFIDF\n",
    "        print(\"Build tags matrix and apply TFIDF...\")\n",
    "        icm_tag = dataset.build_tags_matrix()\n",
    "        #tag_weight = np.array(urm.dot(icm_tag.transpose()).sum(axis=0)).squeeze()\n",
    "        #print(tag_weight[tag_weight>5].shape)\n",
    "        #icm_tag = icm_tag[tag_weight>5].multiply(tag_weight[tag_weight>5])\n",
    "        tags = applyTFIDF(icm_tag, norm='l1')\n",
    "        #tags = icm_tag[tag_weight>5]\n",
    "        # Before stacking tags with the rest of the ICM, we keep only\n",
    "        # the top K tags for each item. This way we try to reduce the\n",
    "        # natural noise added by such sparse features.\n",
    "        tags = top_k_filtering(tags.transpose(), topK=topK_tag).transpose()\n",
    "        #tags.data = tags.data / np.max(tags.data)\n",
    "        #newvalue= (max'-min')/(max-min)*(value-max)+max'\n",
    "\n",
    "        # User augmented UCM\n",
    "        # print(\"Building User augmented ICM\")\n",
    "        # ucm = dataset.build_ucm()\n",
    "        # ua_icm = user_augmented_icm(urm, ucm)\n",
    "        # ua_icm = top_k_filtering(ua_icm.transpose(), topK=55).transpose()\n",
    "\n",
    "        # stack all\n",
    "        icm = vstack([icm, tags, urm * 1], format='csr')\n",
    "        # icm = vstack([icm, tags, applyTFIDF(urm)], format='csr')\n",
    "\n",
    "        S = compute_cosine(icm.transpose()[[dataset.get_track_index_from_id(x)\n",
    "                                            for x in self.tr_id_list]],\n",
    "                       icm,\n",
    "                       k_filtering=self.k_filtering,\n",
    "                       shrinkage=self.shrinkage,\n",
    "                       n_threads=4,\n",
    "                       chunksize=1000)\n",
    "        s_norm = S.sum(axis=1)\n",
    "\n",
    "        # Normalize S\n",
    "        S = S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "        print(\"Similarity matrix ready!\")\n",
    "\n",
    "        # Keep only the target playlists in the URM\n",
    "        urm_cleaned = urm[[dataset.get_playlist_index_from_id(x)\n",
    "                           for x in self.pl_id_list]]\n",
    "        self.S = S.transpose()\n",
    "\n",
    "        # Compute ratings\n",
    "        R_hat = urm_cleaned.dot(S.transpose().tocsc()).tocsr()\n",
    "        print(\"R_hat done\")\n",
    "\n",
    "        # Remove the entries in R_hat that are already present in the URM\n",
    "        urm_cleaned = urm_cleaned[:, [dataset.get_track_index_from_id(x)\n",
    "                                      for x in self.tr_id_list]]\n",
    "        R_hat[urm_cleaned.nonzero()] = 0\n",
    "        R_hat.eliminate_zeros()\n",
    "\n",
    "        print(\"Shape of final matrix: \", R_hat.shape)\n",
    "        self.R_hat = R_hat\n",
    "\n",
    "    def getW(self):\n",
    "        \"\"\"\n",
    "        Returns the similary matrix with dimensions I x I\n",
    "        S is IxT\n",
    "        \"\"\"\n",
    "        return self.S.tocsr()\n",
    "\n",
    "    def predict(self, at=5):\n",
    "        \"\"\"\n",
    "        returns a dictionary of\n",
    "        'pl_id': ['tr_1', 'tr_at'] for each playlist in target playlist\n",
    "        \"\"\"\n",
    "        recs = {}\n",
    "        for i in range(0, self.R_hat.shape[0]):\n",
    "            pl_id = self.pl_id_list[i]\n",
    "            pl_row = self.R_hat.data[self.R_hat.indptr[i]:\n",
    "                                     self.R_hat.indptr[i + 1]]\n",
    "            # get top 5 indeces. argsort, flip and get first at-1 items\n",
    "            sorted_row_idx = np.flip(pl_row.argsort(), axis=0)[0:at]\n",
    "            track_cols = [self.R_hat.indices[self.R_hat.indptr[i] + x]\n",
    "                          for x in sorted_row_idx]\n",
    "            tracks_ids = [self.tr_id_list[x] for x in track_cols]\n",
    "            recs[pl_id] = tracks_ids\n",
    "        return recs\n",
    "\n",
    "    def getR_hat(self):\n",
    "        return self.R_hat\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Returns the complete R_hat\n",
    "        \"\"\"\n",
    "        return self.R_hat.copy()\n",
    "\n",
    "\n",
    "def applyTFIDF(matrix, norm='l1'):\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    transformer = TfidfTransformer(norm=norm, use_idf=True,\n",
    "                                   smooth_idf=True, sublinear_tf=False)\n",
    "    tfidf = transformer.fit_transform(matrix.transpose())\n",
    "    return tfidf.transpose()\n",
    "\n",
    "\n",
    "def produceCsv():\n",
    "    # export csv\n",
    "    dataset = Dataset(load_tags=True,\n",
    "                      filter_tag=False,\n",
    "                      weight_tag=False)\n",
    "    dataset.set_track_attr_weights_2(1.0, 1.0, 0.0, 0.0, 0.0,\n",
    "                                     1.0, 1.0, 0.0, 0.0)\n",
    "    cbf_exporter = ContentBasedFiltering()\n",
    "    urm = dataset.build_train_matrix()\n",
    "    tg_playlist = list(dataset.target_playlists.keys())\n",
    "    tg_tracks = list(dataset.target_tracks.keys())\n",
    "    # Train the model with the best shrinkage found in cross-validation\n",
    "    cbf_exporter.fit(urm,\n",
    "                     tg_playlist,\n",
    "                     tg_tracks,\n",
    "                     dataset)\n",
    "    recs = cbf_exporter.predict()\n",
    "    with open('submission_cbf.csv', mode='w', newline='') as out:\n",
    "        fieldnames = ['playlist_id', 'track_ids']\n",
    "        writer = csv.DictWriter(out, fieldnames=fieldnames, delimiter=',')\n",
    "        writer.writeheader()\n",
    "        for k in tg_playlist:\n",
    "            track_ids = ''\n",
    "            for r in recs[k]:\n",
    "                track_ids = track_ids + r + ' '\n",
    "            writer.writerow({'playlist_id': k,\n",
    "                             'track_ids': track_ids[:-1]})\n",
    "\n",
    "\n",
    "def evaluateMap():\n",
    "    from src.utils.evaluator import Evaluator\n",
    "    dataset = Dataset(load_tags=True,\n",
    "                      filter_tag=False,\n",
    "                      weight_tag=False)\n",
    "    dataset.set_track_attr_weights_2(1.0, 1.0, 0.0, 0.0, 0.0,\n",
    "                                     1.0, 1.0, 0.0, 0.0)\n",
    "    # seed = 0xcafebabe\n",
    "    # print(\"Evaluating with initial seed: {}\".format(seed))\n",
    "    ev = Evaluator(seed=False)\n",
    "    ev.cross_validation(5, dataset.train_final.copy())\n",
    "    cbf = ContentBasedFiltering()\n",
    "    for i in range(0, 5):\n",
    "        urm, tg_tracks, tg_playlist = ev.get_fold(dataset)\n",
    "        cbf.fit(urm,\n",
    "                list(tg_playlist),\n",
    "                list(tg_tracks),\n",
    "                dataset)\n",
    "        recs = cbf.predict()\n",
    "        ev.evaluate_fold(recs)\n",
    "\n",
    "    map_at_five = ev.get_mean_map()\n",
    "    print(\"MAP@5 \", map_at_five)\n",
    "\n",
    "\n",
    "def crossValidation():\n",
    "    from src.utils.evaluator import Evaluator\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Based Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ibs(urm, dataset):\n",
    "    urm_sim = applyTFIDF(urm)\n",
    "    #urm_sim = top_k_filtering(urm_sim.transpose()).transpose()\n",
    "    S = compute_cosine(urm_sim.transpose()[[dataset.get_track_index_from_id(x)\n",
    "                                    for x in tg_tracks]],\n",
    "                       urm_sim,\n",
    "                       k_filtering=100,\n",
    "                       shrinkage=10,\n",
    "                       n_threads=4,\n",
    "                       chunksize=1000)\n",
    "    s_norm = S.sum(axis=1)\n",
    "    s_norm[s_norm==0] = 1\n",
    "    # Normalize S\n",
    "    S = S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "    print(\"Similarity matrix ready!\")\n",
    "    return S.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Based Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ubs(urm, ucm, dataset):\n",
    "    ucm = dataset.build_ucm()\n",
    "    iucm = ucm.dot(urm)\n",
    "    iucm = applyTFIDF(iucm)\n",
    "    iucm = top_k_filtering(iucm.transpose(), 100).transpose()\n",
    "    S = compute_cosine(iucm.transpose()[[dataset.get_track_index_from_id(x)\n",
    "                                                for x in tg_tracks]],\n",
    "                           iucm,\n",
    "                           k_filtering=100,\n",
    "                           shrinkage=10,\n",
    "                           n_threads=4,\n",
    "                           chunksize=1000)\n",
    "    s_norm = S.sum(axis=1)\n",
    "    s_norm[s_norm==0] = 1\n",
    "    print(\"S done\")\n",
    "    # Normalize S\n",
    "    S = S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "    print(\"Similarity matrix ready!\")\n",
    "    return S.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Content Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icm_sim(icm, dataset):\n",
    "    icm_tag = dataset.build_tags_matrix()\n",
    "    #tag_weight = np.array(urm.dot(icm_tag.transpose()).sum(axis=0)).squeeze()\n",
    "    #print(tag_weight[tag_weight>5].shape)\n",
    "    #icm_tag = icm_tag[tag_weight>5].multiply(tag_weight[tag_weight>5])\n",
    "    tags = applyTFIDF(icm_tag, norm='l1')\n",
    "    #tags = icm_tag[tag_weight>5]\n",
    "    # Before stacking tags with the rest of the ICM, we keep only\n",
    "    # the top K tags for each item. This way we try to reduce the\n",
    "    # natural noise added by such sparse features.\n",
    "    tags = top_k_filtering(tags.transpose(), topK=55).transpose()\n",
    "    #tags.data = tags.data / np.max(tags.data)\n",
    "    #newvalue= (max'-min')/(max-min)*(value-max)+max'\n",
    "\n",
    "    # User augmented UCM\n",
    "    # print(\"Building User augmented ICM\")\n",
    "    # ucm = dataset.build_ucm()\n",
    "    # ua_icm = user_augmented_icm(urm, ucm)\n",
    "    # ua_icm = top_k_filtering(ua_icm.transpose(), topK=55).transpose()\n",
    "\n",
    "    # stack all\n",
    "    icm = vstack([icm, tags*0.4], format='csr')\n",
    "    #icm = applyTFIDF(icm)\n",
    "    #icm = top_k_filtering(icm.transpose(), topK=200).transpose()\n",
    "    # icm = vstack([icm, tags, applyTFIDF(urm)], format='csr')\n",
    "\n",
    "    S = compute_cosine(icm.transpose()[[dataset.get_track_index_from_id(x)\n",
    "                                        for x in tg_tracks]],\n",
    "                   icm,\n",
    "                   k_filtering=100,\n",
    "                   shrinkage=10,\n",
    "                   n_threads=4,\n",
    "                   chunksize=1000)\n",
    "    s_norm = S.sum(axis=1)\n",
    "    s_norm[s_norm==0] = 1\n",
    "    print(\"S done\")\n",
    "    # Normalize S\n",
    "    S = S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "    print(\"Similarity matrix ready!\")\n",
    "    return S.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MF-Based Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBF started\n",
      "Build tags matrix and apply TFIDF...\n",
      "Running 4 workers...\n",
      "[ 7554 ] Building cosine similarity matrix for [0, 1000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [25000, 26000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [50000, 51000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [1000, 2000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [26000, 27000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [75000, 76000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [2000, 3000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [51000, 52000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [27000, 28000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [3000, 4000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [52000, 53000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [76000, 77000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [28000, 29000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [4000, 5000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [53000, 54000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [29000, 30000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [77000, 78000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [5000, 6000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [54000, 55000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [30000, 31000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [6000, 7000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [78000, 79000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [55000, 56000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [31000, 32000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [7000, 8000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [79000, 80000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [32000, 33000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [8000, 9000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [56000, 57000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [33000, 34000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [80000, 81000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [9000, 10000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [57000, 58000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [34000, 35000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [81000, 82000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [10000, 11000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [58000, 59000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [35000, 36000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [82000, 83000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [11000, 12000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [59000, 60000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [36000, 37000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [83000, 84000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [12000, 13000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [60000, 61000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [37000, 38000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [84000, 85000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [13000, 14000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [85000, 86000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [61000, 62000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [38000, 39000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [14000, 15000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [86000, 87000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [62000, 63000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [39000, 40000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [15000, 16000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [87000, 88000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [63000, 64000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [40000, 41000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [16000, 17000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [88000, 89000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [41000, 42000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [64000, 65000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [17000, 18000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [89000, 90000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [65000, 66000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [18000, 19000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [42000, 43000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [90000, 91000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [43000, 44000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [66000, 67000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [19000, 20000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [91000, 92000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [44000, 45000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [20000, 21000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [67000, 68000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [92000, 93000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [45000, 46000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [21000, 22000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [46000, 47000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [68000, 69000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [93000, 94000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [22000, 23000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [47000, 48000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [69000, 70000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [94000, 95000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [23000, 24000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [95000, 96000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [48000, 49000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [70000, 71000)...\n",
      "[ 7554 ] Building cosine similarity matrix for [24000, 25000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [96000, 97000)...\n",
      "[ 7555 ] Building cosine similarity matrix for [49000, 50000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [71000, 72000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [97000, 98000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [98000, 99000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [72000, 73000)...\n",
      "[ 7557 ] Building cosine similarity matrix for [99000, 100000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [73000, 74000)...\n",
      "[ 7556 ] Building cosine similarity matrix for [74000, 75000)...\n",
      "Similarity matrix ready!\n",
      "R_hat done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanueleghelfi/Development/RS/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final matrix:  (57561, 100000)\n",
      "1231858\n"
     ]
    }
   ],
   "source": [
    "from src.CBF.CBF_MF import ContentBasedFiltering as CBF\n",
    "from src.MF.MF_BPR.MF_BPR import MF_BPR\n",
    "cbf = CBF()\n",
    "    \n",
    "cbf.fit(urm, tg_playlist,\n",
    "        tg_tracks,\n",
    "        dataset)\n",
    "\n",
    "# get R_hat\n",
    "R_hat_aug = cbf.getR_hat()\n",
    "print(R_hat_aug.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MF_BPR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000000 ( 67.65% ) in 493.97 seconds. Sample per second: 10122\n",
      "Processed 7391148 ( 100.00% ) in 239.09 seconds. Sample per second: 10096\n",
      "Training finished\n",
      "R_hat done\n",
      "MAP@5: 0.07459871516467634\n",
      "Computing dot product for chunk [0, 1000)...\n",
      "Computing dot product for chunk [1000, 2000)...\n",
      "Computing dot product for chunk [2000, 3000)...\n",
      "Computing dot product for chunk [3000, 4000)...\n",
      "Computing dot product for chunk [4000, 5000)...\n",
      "Computing dot product for chunk [5000, 6000)...\n",
      "Computing dot product for chunk [6000, 7000)...\n",
      "Computing dot product for chunk [7000, 8000)...\n",
      "Computing dot product for chunk [8000, 9000)...\n",
      "Computing dot product for chunk [9000, 10000)...\n",
      "Computing dot product for chunk [10000, 11000)...\n",
      "Computing dot product for chunk [11000, 12000)...\n",
      "Computing dot product for chunk [12000, 13000)...\n",
      "Computing dot product for chunk [13000, 14000)...\n",
      "Computing dot product for chunk [14000, 15000)...\n",
      "Computing dot product for chunk [15000, 16000)...\n",
      "Computing dot product for chunk [16000, 17000)...\n",
      "Computing dot product for chunk [17000, 18000)...\n",
      "Computing dot product for chunk [18000, 19000)...\n",
      "Computing dot product for chunk [19000, 20000)...\n",
      "Computing dot product for chunk [20000, 21000)...\n",
      "Computing dot product for chunk [21000, 22000)...\n",
      "Computing dot product for chunk [22000, 23000)...\n",
      "Computing dot product for chunk [23000, 24000)...\n",
      "Computing dot product for chunk [24000, 25000)...\n",
      "Computing dot product for chunk [25000, 25734)...\n",
      "S done\n",
      "MAP@5: 0.07773117987694571\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MF_BPR' object has no attribute 'S'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9cc517eb66d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mS_mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MF_BPR' object has no attribute 'S'"
     ]
    }
   ],
   "source": [
    "# MAP@5: 0.08256503053607782 with 500 factors after 10 epochs\n",
    "# MAP@5: 0.08594586443489391 with 500 factors afetr 4 epochs no_components=500, epoch_multiplier=2, l_rate=1e-2\n",
    "mf.fit(R_hat_aug, dataset, list(tg_playlist), list(tg_tracks), n_epochs=1, no_components=500, epoch_multiplier=6, l_rate=1e-2, use_icm=False)\n",
    "recs = mf.predict_dot_custom(urm)\n",
    "ev.evaluate_fold(recs)\n",
    "\n",
    "# MAP@5: 0.09407901681369218 with neighborhood\n",
    "# MAP@5: 0.09854105406016736 with neighborhood after 4 epochs\n",
    "recs = mf.predict_knn_custom(urm)\n",
    "ev.evaluate_fold(recs)\n",
    "\n",
    "S_mf = mf.S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIM Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the ICM...\n",
      "Running fit process.\n",
      "Processed 500000 ( 29.85% ) in 41.19 seconds. Sample per second: 12138\n",
      "Processed 1000000 ( 59.70% ) in 11.96 seconds. Sample per second: 18883\n",
      "Processed 1500000 ( 89.54% ) in 10.11 seconds. Sample per second: 24150\n",
      "Processed 1675142 ( 100.00% ) in 3.38 seconds. Sample per second: 25621\n",
      "Return S matrix to python caller...\n",
      "Epoch 0 of 50 complete in 1.30 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.65 seconds. Sample per second: 57799\n",
      "Processed 1000000 ( 59.70% ) in 6.16 seconds. Sample per second: 70643\n",
      "Processed 1500000 ( 89.54% ) in 5.76 seconds. Sample per second: 75919\n",
      "Processed 1675142 ( 100.00% ) in 2.73 seconds. Sample per second: 77080\n",
      "Return S matrix to python caller...\n",
      "Epoch 1 of 50 complete in 0.70 minutes\n",
      "Processed 500000 ( 29.85% ) in 6.97 seconds. Sample per second: 71728\n",
      "Processed 1000000 ( 59.70% ) in 6.63 seconds. Sample per second: 79182\n",
      "Processed 1500000 ( 89.54% ) in 6.52 seconds. Sample per second: 81005\n",
      "Processed 1675142 ( 100.00% ) in 2.65 seconds. Sample per second: 81130\n",
      "Return S matrix to python caller...\n",
      "Epoch 2 of 50 complete in 0.76 minutes\n",
      "Processed 500000 ( 29.85% ) in 6.47 seconds. Sample per second: 77331\n",
      "Processed 1000000 ( 59.70% ) in 6.57 seconds. Sample per second: 79570\n",
      "Processed 1500000 ( 89.54% ) in 6.87 seconds. Sample per second: 79471\n",
      "Processed 1675142 ( 100.00% ) in 2.94 seconds. Sample per second: 80013\n",
      "Return S matrix to python caller...\n",
      "Epoch 3 of 50 complete in 0.82 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.52 seconds. Sample per second: 58652\n",
      "Processed 1000000 ( 59.70% ) in 6.52 seconds. Sample per second: 68859\n",
      "Processed 1500000 ( 89.54% ) in 6.80 seconds. Sample per second: 72101\n",
      "Processed 1675142 ( 100.00% ) in 2.89 seconds. Sample per second: 73178\n",
      "Return S matrix to python caller...\n",
      "Epoch 4 of 50 complete in 0.86 minutes\n",
      "Processed 500000 ( 29.85% ) in 7.57 seconds. Sample per second: 66012\n",
      "Processed 1000000 ( 59.70% ) in 7.35 seconds. Sample per second: 69708\n",
      "Processed 1500000 ( 89.54% ) in 6.89 seconds. Sample per second: 71799\n",
      "Processed 1675142 ( 100.00% ) in 3.09 seconds. Sample per second: 72544\n",
      "Return S matrix to python caller...\n",
      "Epoch 5 of 50 complete in 0.86 minutes\n",
      "Processed 500000 ( 29.85% ) in 12.46 seconds. Sample per second: 40129\n",
      "Processed 1000000 ( 59.70% ) in 7.51 seconds. Sample per second: 51249\n",
      "Processed 1500000 ( 89.54% ) in 7.28 seconds. Sample per second: 57075\n",
      "Processed 1675142 ( 100.00% ) in 2.57 seconds. Sample per second: 58624\n",
      "Return S matrix to python caller...\n",
      "Epoch 6 of 50 complete in 0.98 minutes\n",
      "Processed 500000 ( 29.85% ) in 7.54 seconds. Sample per second: 66344\n",
      "Processed 1000000 ( 59.70% ) in 7.05 seconds. Sample per second: 71199\n",
      "Processed 1500000 ( 89.54% ) in 6.34 seconds. Sample per second: 73753\n",
      "Processed 1675142 ( 100.00% ) in 2.45 seconds. Sample per second: 74606\n",
      "Return S matrix to python caller...\n",
      "Epoch 7 of 50 complete in 0.86 minutes\n",
      "Processed 500000 ( 29.85% ) in 7.54 seconds. Sample per second: 66348\n",
      "Processed 1000000 ( 59.70% ) in 7.22 seconds. Sample per second: 70347\n",
      "Processed 1500000 ( 89.54% ) in 6.34 seconds. Sample per second: 73763\n",
      "Processed 1675142 ( 100.00% ) in 2.52 seconds. Sample per second: 74391\n",
      "Return S matrix to python caller...\n",
      "Epoch 8 of 50 complete in 0.90 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.70 seconds. Sample per second: 57483\n",
      "Processed 1000000 ( 59.70% ) in 7.49 seconds. Sample per second: 64551\n",
      "Processed 1500000 ( 89.54% ) in 6.86 seconds. Sample per second: 68630\n",
      "Processed 1675142 ( 100.00% ) in 3.22 seconds. Sample per second: 69177\n",
      "Return S matrix to python caller...\n",
      "Epoch 9 of 50 complete in 0.93 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.35 seconds. Sample per second: 53476\n",
      "Processed 1000000 ( 59.70% ) in 6.94 seconds. Sample per second: 62733\n",
      "Processed 1500000 ( 89.54% ) in 7.24 seconds. Sample per second: 67447\n",
      "Processed 1675142 ( 100.00% ) in 2.41 seconds. Sample per second: 68627\n",
      "Return S matrix to python caller...\n",
      "Evaluating recommendations\n",
      "R_hat evaluated...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanueleghelfi/Development/RS/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.06927693583653736\n",
      "Epoch 10 of 50 complete in 1.13 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.20 seconds. Sample per second: 60957\n",
      "Processed 1000000 ( 59.70% ) in 7.12 seconds. Sample per second: 66158\n",
      "Processed 1500000 ( 89.54% ) in 6.61 seconds. Sample per second: 69399\n",
      "Processed 1675142 ( 100.00% ) in 2.97 seconds. Sample per second: 69882\n",
      "Return S matrix to python caller...\n",
      "Epoch 11 of 50 complete in 0.92 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.85 seconds. Sample per second: 56529\n",
      "Processed 1000000 ( 59.70% ) in 7.13 seconds. Sample per second: 66081\n",
      "Processed 1500000 ( 89.54% ) in 6.49 seconds. Sample per second: 69786\n",
      "Processed 1675142 ( 100.00% ) in 2.82 seconds. Sample per second: 70329\n",
      "Return S matrix to python caller...\n",
      "Epoch 12 of 50 complete in 0.91 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.74 seconds. Sample per second: 57182\n",
      "Processed 1000000 ( 59.70% ) in 7.25 seconds. Sample per second: 65579\n",
      "Processed 1500000 ( 89.54% ) in 6.59 seconds. Sample per second: 69490\n",
      "Processed 1675142 ( 100.00% ) in 2.79 seconds. Sample per second: 70411\n",
      "Return S matrix to python caller...\n",
      "Epoch 13 of 50 complete in 0.90 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.24 seconds. Sample per second: 54101\n",
      "Processed 1000000 ( 59.70% ) in 6.86 seconds. Sample per second: 63066\n",
      "Processed 1500000 ( 89.54% ) in 7.25 seconds. Sample per second: 67423\n",
      "Processed 1675142 ( 100.00% ) in 2.51 seconds. Sample per second: 68352\n",
      "Return S matrix to python caller...\n",
      "Epoch 14 of 50 complete in 0.93 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.10 seconds. Sample per second: 61736\n",
      "Processed 1000000 ( 59.70% ) in 7.12 seconds. Sample per second: 66121\n",
      "Processed 1500000 ( 89.54% ) in 6.53 seconds. Sample per second: 69678\n",
      "Processed 1675142 ( 100.00% ) in 2.82 seconds. Sample per second: 70335\n",
      "Return S matrix to python caller...\n",
      "Epoch 15 of 50 complete in 0.91 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.64 seconds. Sample per second: 57869\n",
      "Processed 1000000 ( 59.70% ) in 7.69 seconds. Sample per second: 63727\n",
      "Processed 1500000 ( 89.54% ) in 7.12 seconds. Sample per second: 67826\n",
      "Processed 1675142 ( 100.00% ) in 2.63 seconds. Sample per second: 68021\n",
      "Return S matrix to python caller...\n",
      "Epoch 16 of 50 complete in 0.95 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.18 seconds. Sample per second: 54471\n",
      "Processed 1000000 ( 59.70% ) in 7.28 seconds. Sample per second: 61426\n",
      "Processed 1500000 ( 89.54% ) in 6.62 seconds. Sample per second: 66327\n",
      "Processed 1675142 ( 100.00% ) in 3.07 seconds. Sample per second: 66816\n",
      "Return S matrix to python caller...\n",
      "Epoch 17 of 50 complete in 0.93 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.50 seconds. Sample per second: 52626\n",
      "Processed 1000000 ( 59.70% ) in 7.49 seconds. Sample per second: 60628\n",
      "Processed 1500000 ( 89.54% ) in 6.86 seconds. Sample per second: 65631\n",
      "Processed 1675142 ( 100.00% ) in 3.08 seconds. Sample per second: 66792\n",
      "Return S matrix to python caller...\n",
      "Epoch 18 of 50 complete in 0.94 minutes\n",
      "Processed 500000 ( 29.85% ) in 7.74 seconds. Sample per second: 64577\n",
      "Processed 1000000 ( 59.70% ) in 8.11 seconds. Sample per second: 66197\n",
      "Processed 1500000 ( 89.54% ) in 6.65 seconds. Sample per second: 69292\n",
      "Processed 1675142 ( 100.00% ) in 3.16 seconds. Sample per second: 69343\n",
      "Return S matrix to python caller...\n",
      "Epoch 19 of 50 complete in 0.93 minutes\n",
      "Processed 500000 ( 29.85% ) in 13.17 seconds. Sample per second: 37962\n",
      "Processed 1000000 ( 59.70% ) in 7.12 seconds. Sample per second: 49697\n",
      "Processed 1500000 ( 89.54% ) in 6.80 seconds. Sample per second: 55973\n",
      "Processed 1675142 ( 100.00% ) in 3.18 seconds. Sample per second: 57402\n",
      "Return S matrix to python caller...\n",
      "Evaluating recommendations\n",
      "R_hat evaluated...\n",
      "MAP@5: 0.07149287491517722\n",
      "Epoch 20 of 50 complete in 1.22 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.46 seconds. Sample per second: 59080\n",
      "Processed 1000000 ( 59.70% ) in 7.93 seconds. Sample per second: 62771\n",
      "Processed 1500000 ( 89.54% ) in 7.15 seconds. Sample per second: 67730\n",
      "Processed 1675142 ( 100.00% ) in 2.57 seconds. Sample per second: 68181\n",
      "Return S matrix to python caller...\n",
      "Epoch 21 of 50 complete in 0.94 minutes\n",
      "Processed 500000 ( 29.85% ) in 10.39 seconds. Sample per second: 48117\n",
      "Processed 1000000 ( 59.70% ) in 7.73 seconds. Sample per second: 56414\n",
      "Processed 1500000 ( 89.54% ) in 7.20 seconds. Sample per second: 61979\n",
      "Processed 1675142 ( 100.00% ) in 2.56 seconds. Sample per second: 63071\n",
      "Return S matrix to python caller...\n",
      "Epoch 22 of 50 complete in 0.97 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.90 seconds. Sample per second: 50506\n",
      "Processed 1000000 ( 59.70% ) in 7.61 seconds. Sample per second: 60195\n",
      "Processed 1500000 ( 89.54% ) in 7.85 seconds. Sample per second: 62897\n",
      "Processed 1675142 ( 100.00% ) in 3.21 seconds. Sample per second: 63904\n",
      "Return S matrix to python caller...\n",
      "Epoch 23 of 50 complete in 0.95 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.68 seconds. Sample per second: 57604\n",
      "Processed 1000000 ( 59.70% ) in 8.29 seconds. Sample per second: 61398\n",
      "Processed 1500000 ( 89.54% ) in 6.48 seconds. Sample per second: 66738\n",
      "Processed 1675142 ( 100.00% ) in 2.88 seconds. Sample per second: 67317\n",
      "Return S matrix to python caller...\n",
      "Epoch 24 of 50 complete in 0.93 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.82 seconds. Sample per second: 56676\n",
      "Processed 1000000 ( 59.70% ) in 8.31 seconds. Sample per second: 61320\n",
      "Processed 1500000 ( 89.54% ) in 6.71 seconds. Sample per second: 66050\n",
      "Processed 1675142 ( 100.00% ) in 3.05 seconds. Sample per second: 66866\n",
      "Return S matrix to python caller...\n",
      "Epoch 25 of 50 complete in 0.93 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.73 seconds. Sample per second: 57274\n",
      "Processed 1000000 ( 59.70% ) in 7.69 seconds. Sample per second: 63753\n",
      "Processed 1500000 ( 89.54% ) in 7.40 seconds. Sample per second: 66976\n",
      "Processed 1675142 ( 100.00% ) in 2.74 seconds. Sample per second: 67719\n",
      "Return S matrix to python caller...\n",
      "Epoch 26 of 50 complete in 0.95 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.72 seconds. Sample per second: 57313\n",
      "Processed 1000000 ( 59.70% ) in 7.39 seconds. Sample per second: 64980\n",
      "Processed 1500000 ( 89.54% ) in 6.81 seconds. Sample per second: 68786\n",
      "Processed 1675142 ( 100.00% ) in 3.14 seconds. Sample per second: 69393\n",
      "Return S matrix to python caller...\n",
      "Epoch 27 of 50 complete in 0.92 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.11 seconds. Sample per second: 54870\n",
      "Processed 1000000 ( 59.70% ) in 7.52 seconds. Sample per second: 60515\n",
      "Processed 1500000 ( 89.54% ) in 7.62 seconds. Sample per second: 63500\n",
      "Processed 1675142 ( 100.00% ) in 3.12 seconds. Sample per second: 64131\n",
      "Return S matrix to python caller...\n",
      "Epoch 28 of 50 complete in 0.95 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.01 seconds. Sample per second: 55524\n",
      "Processed 1000000 ( 59.70% ) in 7.03 seconds. Sample per second: 62367\n",
      "Processed 1500000 ( 89.54% ) in 6.54 seconds. Sample per second: 66563\n",
      "Processed 1675142 ( 100.00% ) in 2.89 seconds. Sample per second: 67311\n",
      "Return S matrix to python caller...\n",
      "Epoch 29 of 50 complete in 0.92 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.02 seconds. Sample per second: 55409\n",
      "Processed 1000000 ( 59.70% ) in 8.28 seconds. Sample per second: 57871\n",
      "Processed 1500000 ( 89.54% ) in 6.83 seconds. Sample per second: 62944\n",
      "Processed 1675142 ( 100.00% ) in 3.20 seconds. Sample per second: 63929\n",
      "Return S matrix to python caller...\n",
      "Evaluating recommendations\n",
      "R_hat evaluated...\n",
      "MAP@5: 0.07239387770489306\n",
      "Epoch 30 of 50 complete in 1.20 minutes\n",
      "Processed 500000 ( 29.85% ) in 10.11 seconds. Sample per second: 49455\n",
      "Processed 1000000 ( 59.70% ) in 8.27 seconds. Sample per second: 54731\n",
      "Processed 1500000 ( 89.54% ) in 7.83 seconds. Sample per second: 58063\n",
      "Processed 1675142 ( 100.00% ) in 3.31 seconds. Sample per second: 59170\n",
      "Return S matrix to python caller...\n",
      "Epoch 31 of 50 complete in 1.04 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.93 seconds. Sample per second: 56022\n",
      "Processed 1000000 ( 59.70% ) in 8.42 seconds. Sample per second: 60909\n",
      "Processed 1500000 ( 89.54% ) in 7.23 seconds. Sample per second: 64564\n",
      "Processed 1675142 ( 100.00% ) in 2.52 seconds. Sample per second: 65642\n",
      "Return S matrix to python caller...\n",
      "Epoch 32 of 50 complete in 0.99 minutes\n",
      "Processed 500000 ( 29.85% ) in 12.03 seconds. Sample per second: 41546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 ( 59.70% ) in 6.96 seconds. Sample per second: 52739\n",
      "Processed 1500000 ( 89.54% ) in 8.27 seconds. Sample per second: 57089\n",
      "Processed 1675142 ( 100.00% ) in 2.92 seconds. Sample per second: 57913\n",
      "Return S matrix to python caller...\n",
      "Epoch 33 of 50 complete in 1.13 minutes\n",
      "Processed 500000 ( 29.85% ) in 10.01 seconds. Sample per second: 49957\n",
      "Processed 1000000 ( 59.70% ) in 8.09 seconds. Sample per second: 55277\n",
      "Processed 1500000 ( 89.54% ) in 7.79 seconds. Sample per second: 58173\n",
      "Processed 1675142 ( 100.00% ) in 3.03 seconds. Sample per second: 59754\n",
      "Return S matrix to python caller...\n",
      "Epoch 34 of 50 complete in 1.05 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.37 seconds. Sample per second: 53384\n",
      "Processed 1000000 ( 59.70% ) in 8.58 seconds. Sample per second: 56879\n",
      "Processed 1500000 ( 89.54% ) in 7.88 seconds. Sample per second: 60285\n",
      "Processed 1675142 ( 100.00% ) in 3.46 seconds. Sample per second: 61008\n",
      "Return S matrix to python caller...\n",
      "Epoch 35 of 50 complete in 1.04 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.78 seconds. Sample per second: 51099\n",
      "Processed 1000000 ( 59.70% ) in 9.13 seconds. Sample per second: 55151\n",
      "Processed 1500000 ( 89.54% ) in 7.24 seconds. Sample per second: 59423\n",
      "Processed 1675142 ( 100.00% ) in 2.53 seconds. Sample per second: 60845\n",
      "Return S matrix to python caller...\n",
      "Epoch 36 of 50 complete in 1.05 minutes\n",
      "Processed 500000 ( 29.85% ) in 11.66 seconds. Sample per second: 42871\n",
      "Processed 1000000 ( 59.70% ) in 9.00 seconds. Sample per second: 49990\n",
      "Processed 1500000 ( 89.54% ) in 7.74 seconds. Sample per second: 54074\n",
      "Processed 1675142 ( 100.00% ) in 3.55 seconds. Sample per second: 54833\n",
      "Return S matrix to python caller...\n",
      "Epoch 37 of 50 complete in 1.11 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.90 seconds. Sample per second: 50488\n",
      "Processed 1000000 ( 59.70% ) in 8.85 seconds. Sample per second: 56031\n",
      "Processed 1500000 ( 89.54% ) in 10.02 seconds. Sample per second: 55524\n",
      "Processed 1675142 ( 100.00% ) in 2.59 seconds. Sample per second: 56615\n",
      "Return S matrix to python caller...\n",
      "Epoch 38 of 50 complete in 1.11 minutes\n",
      "Processed 500000 ( 29.85% ) in 11.25 seconds. Sample per second: 44447\n",
      "Processed 1000000 ( 59.70% ) in 8.70 seconds. Sample per second: 50762\n",
      "Processed 1500000 ( 89.54% ) in 7.94 seconds. Sample per second: 55671\n",
      "Processed 1675142 ( 100.00% ) in 3.38 seconds. Sample per second: 57009\n",
      "Return S matrix to python caller...\n",
      "Epoch 39 of 50 complete in 1.15 minutes\n",
      "Processed 500000 ( 29.85% ) in 12.83 seconds. Sample per second: 38979\n",
      "Processed 1000000 ( 59.70% ) in 9.17 seconds. Sample per second: 47234\n",
      "Processed 1500000 ( 89.54% ) in 7.45 seconds. Sample per second: 52715\n",
      "Processed 1675142 ( 100.00% ) in 3.13 seconds. Sample per second: 53818\n",
      "Return S matrix to python caller...\n",
      "Evaluating recommendations\n",
      "R_hat evaluated...\n",
      "MAP@5: 0.07296690039960776\n",
      "Epoch 40 of 50 complete in 1.38 minutes\n",
      "Processed 500000 ( 29.85% ) in 11.65 seconds. Sample per second: 42912\n",
      "Processed 1000000 ( 59.70% ) in 9.24 seconds. Sample per second: 49406\n",
      "Processed 1500000 ( 89.54% ) in 7.47 seconds. Sample per second: 54614\n",
      "Processed 1675142 ( 100.00% ) in 3.02 seconds. Sample per second: 55802\n",
      "Return S matrix to python caller...\n",
      "Epoch 41 of 50 complete in 1.08 minutes\n",
      "Processed 500000 ( 29.85% ) in 10.49 seconds. Sample per second: 47651\n",
      "Processed 1000000 ( 59.70% ) in 8.03 seconds. Sample per second: 55473\n",
      "Processed 1500000 ( 89.54% ) in 6.72 seconds. Sample per second: 60675\n",
      "Processed 1675142 ( 100.00% ) in 3.07 seconds. Sample per second: 61883\n",
      "Return S matrix to python caller...\n",
      "Epoch 42 of 50 complete in 0.98 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.73 seconds. Sample per second: 57266\n",
      "Processed 1000000 ( 59.70% ) in 8.39 seconds. Sample per second: 61020\n",
      "Processed 1500000 ( 89.54% ) in 7.58 seconds. Sample per second: 63624\n",
      "Processed 1675142 ( 100.00% ) in 3.17 seconds. Sample per second: 63999\n",
      "Return S matrix to python caller...\n",
      "Epoch 43 of 50 complete in 1.05 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.34 seconds. Sample per second: 53511\n",
      "Processed 1000000 ( 59.70% ) in 8.40 seconds. Sample per second: 57485\n",
      "Processed 1500000 ( 89.54% ) in 8.55 seconds. Sample per second: 58718\n",
      "Processed 1675142 ( 100.00% ) in 2.95 seconds. Sample per second: 59938\n",
      "Return S matrix to python caller...\n",
      "Epoch 44 of 50 complete in 1.00 minutes\n",
      "Processed 500000 ( 29.85% ) in 9.25 seconds. Sample per second: 54031\n",
      "Processed 1000000 ( 59.70% ) in 7.42 seconds. Sample per second: 60892\n",
      "Processed 1500000 ( 89.54% ) in 7.02 seconds. Sample per second: 65154\n",
      "Processed 1675142 ( 100.00% ) in 2.48 seconds. Sample per second: 65741\n",
      "Return S matrix to python caller...\n",
      "Epoch 45 of 50 complete in 0.96 minutes\n",
      "Processed 500000 ( 29.85% ) in 12.57 seconds. Sample per second: 39767\n",
      "Processed 1000000 ( 59.70% ) in 8.19 seconds. Sample per second: 49517\n",
      "Processed 1500000 ( 89.54% ) in 7.39 seconds. Sample per second: 54767\n",
      "Processed 1675142 ( 100.00% ) in 2.99 seconds. Sample per second: 55850\n",
      "Return S matrix to python caller...\n",
      "Epoch 46 of 50 complete in 1.10 minutes\n",
      "Processed 500000 ( 29.85% ) in 11.59 seconds. Sample per second: 43157\n",
      "Processed 1000000 ( 59.70% ) in 8.60 seconds. Sample per second: 51010\n",
      "Processed 1500000 ( 89.54% ) in 8.79 seconds. Sample per second: 53975\n",
      "Processed 1675142 ( 100.00% ) in 3.61 seconds. Sample per second: 54729\n",
      "Return S matrix to python caller...\n",
      "Epoch 47 of 50 complete in 1.12 minutes\n",
      "Processed 500000 ( 29.85% ) in 8.44 seconds. Sample per second: 59228\n",
      "Processed 1000000 ( 59.70% ) in 8.13 seconds. Sample per second: 61978\n",
      "Processed 1500000 ( 89.54% ) in 7.34 seconds. Sample per second: 64276\n",
      "Processed 1675142 ( 100.00% ) in 2.90 seconds. Sample per second: 64683\n",
      "Return S matrix to python caller...\n",
      "Epoch 48 of 50 complete in 1.05 minutes\n",
      "Processed 500000 ( 29.85% ) in 11.02 seconds. Sample per second: 45378\n",
      "Processed 1000000 ( 59.70% ) in 8.08 seconds. Sample per second: 52401\n",
      "Processed 1500000 ( 89.54% ) in 7.36 seconds. Sample per second: 56907\n",
      "Processed 1675142 ( 100.00% ) in 2.81 seconds. Sample per second: 58140\n",
      "Return S matrix to python caller...\n",
      "Epoch 49 of 50 complete in 1.07 minutes\n",
      "Fit completed in 49.78 minutes\n",
      "S done\n"
     ]
    }
   ],
   "source": [
    "from src.ML.BPRSLIM import BPRSLIM\n",
    "\n",
    "\n",
    "dataset.set_track_attr_weights_2(1, 1, 0, 0, 0, 0, 0, 0, 0)\n",
    "#ds.set_track_attr_weights(1, 1, 0, 0, 1)\n",
    "print('Building the ICM...')\n",
    "icm = dataset.build_icm()\n",
    "\n",
    "icm_tag = dataset.build_tags_matrix()\n",
    "\n",
    "tags = applyTFIDF(icm_tag, norm='l1')\n",
    "\n",
    "# Before stacking tags with the rest of the ICM, we keep only\n",
    "# the top K tags for each item. This way we try to reduce the\n",
    "# natural noise added by such sparse features.\n",
    "tags = top_k_filtering(tags.transpose(), topK=55).transpose()\n",
    "tags.data = np.ones_like(tags.data)\n",
    "\n",
    "# stack all\n",
    "icm = vstack([icm, tags], format='csr')\n",
    "\n",
    "recommender = BPRSLIM(epochs=50,\n",
    "                      epochMultiplier=1.0,\n",
    "                      sgd_mode='rmsprop',\n",
    "                      learning_rate=5e-02,\n",
    "                      topK=300,\n",
    "                      urmSamplingChances=1 / 5,\n",
    "                      icmSamplingChances=4 / 5)\n",
    "recommender.set_evaluation_every(10, ev)\n",
    "recommender.fit(urm.tocsr(),\n",
    "                icm.tocsr(),\n",
    "                tg_playlist,\n",
    "                tg_tracks,\n",
    "                dataset)\n",
    "\n",
    "S_bprslim = recommender.getParameters()\n",
    "S_bprslim = S_bprslim[:,[dataset.get_track_index_from_id(x) for x in tg_tracks]]\n",
    "\n",
    "# keep only 100 elements\n",
    "S_bprslim = top_k_filtering(S_bprslim.transpose(), 100).transpose()\n",
    "\n",
    "# normalize\n",
    "s_norm = S_bprslim.sum(axis=0)\n",
    "s_norm[s_norm==0] = 1\n",
    "print(\"S done\")\n",
    "\n",
    "S_bprslim = S_bprslim.multiply(csr_matrix(np.reciprocal(s_norm)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "hey\n",
      "File found, retrieving urm from it.\n",
      "Load from file takes 0.25 seconds\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from src.utils.evaluator import Evaluator\n",
    "from src.utils.loader import *\n",
    "print(\"started\")\n",
    "print(\"hey\")\n",
    "dataset = Dataset(load_tags=True,\n",
    "                  filter_tag=False,\n",
    "                  weight_tag=False)\n",
    "dataset.set_track_attr_weights_2(1.5, 1.6, 0, 0, 0.0,\n",
    "                                 1.0, 0, 0.0, 0.0)\n",
    "# seed = 0xcafebabe\n",
    "# print(\"Evaluating with initial seed: {}\".format(seed))\n",
    "ev = Evaluator(seed=False)\n",
    "ev.cross_validation(5, dataset.train_final.copy())\n",
    "urm, tg_tracks, tg_playlist = ev.get_fold(dataset)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start exporting\n",
      "File found, retrieving urm from it.\n",
      "Load from file takes 0.44 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Start exporting\")\n",
    "dataset = Dataset(load_tags=True,\n",
    "                  filter_tag=False,\n",
    "                  weight_tag=False)\n",
    "dataset.set_track_attr_weights_2(1.5, 1.6, 0, 0, 0.0,\n",
    "                                 1.0, 0, 0.0, 0.0)\n",
    "# seed = 0xcafebabe\n",
    "# print(\"Evaluating with initial seed: {}\".format(seed))\n",
    "urm = dataset.build_train_matrix()\n",
    "tg_playlist = list(dataset.target_playlists.keys())\n",
    "tg_tracks = list(dataset.target_tracks.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "CBF started\n",
      "Build tags matrix and apply TFIDF...\n",
      "Running 4 workers...\n",
      "[ 896 ] Building cosine similarity matrix for [0, 1000)...\n",
      "[ 897 ] Building cosine similarity matrix for [8048, 9048)...\n",
      "[ 898 ] Building cosine similarity matrix for [16096, 17096)...\n",
      "[ 899 ] Building cosine similarity matrix for [24144, 25144)...\n",
      "[ 896 ] Building cosine similarity matrix for [1000, 2000)...\n",
      "[ 897 ] Building cosine similarity matrix for [9048, 10048)...\n",
      "[ 898 ] Building cosine similarity matrix for [17096, 18096)...\n",
      "[ 896 ] Building cosine similarity matrix for [2000, 3000)...\n",
      "[ 899 ] Building cosine similarity matrix for [25144, 26144)...\n",
      "[ 897 ] Building cosine similarity matrix for [10048, 11048)...\n",
      "[ 898 ] Building cosine similarity matrix for [18096, 19096)...\n",
      "[ 896 ] Building cosine similarity matrix for [3000, 4000)...\n",
      "[ 899 ] Building cosine similarity matrix for [26144, 27144)...\n",
      "[ 897 ] Building cosine similarity matrix for [11048, 12048)...\n",
      "[ 898 ] Building cosine similarity matrix for [19096, 20096)...\n",
      "[ 899 ] Building cosine similarity matrix for [27144, 28144)...\n",
      "[ 896 ] Building cosine similarity matrix for [4000, 5000)...\n",
      "[ 897 ] Building cosine similarity matrix for [12048, 13048)...\n",
      "[ 898 ] Building cosine similarity matrix for [20096, 21096)...\n",
      "[ 896 ] Building cosine similarity matrix for [5000, 6000)...\n",
      "[ 899 ] Building cosine similarity matrix for [28144, 29144)...\n",
      "[ 897 ] Building cosine similarity matrix for [13048, 14048)...\n",
      "[ 898 ] Building cosine similarity matrix for [21096, 22096)...\n",
      "[ 896 ] Building cosine similarity matrix for [6000, 7000)...\n",
      "[ 899 ] Building cosine similarity matrix for [29144, 30144)...\n",
      "[ 897 ] Building cosine similarity matrix for [14048, 15048)...\n",
      "[ 898 ] Building cosine similarity matrix for [22096, 23096)...\n",
      "[ 896 ] Building cosine similarity matrix for [7000, 8000)...\n",
      "[ 899 ] Building cosine similarity matrix for [30144, 31144)...\n",
      "[ 897 ] Building cosine similarity matrix for [15048, 16048)...\n",
      "[ 898 ] Building cosine similarity matrix for [23096, 24096)...\n",
      "[ 896 ] Building cosine similarity matrix for [8000, 8048)...\n",
      "[ 899 ] Building cosine similarity matrix for [31144, 32144)...\n",
      "[ 896 ] Building cosine similarity matrix for [32192, 32195)...\n",
      "[ 897 ] Building cosine similarity matrix for [16048, 16096)...\n",
      "[ 898 ] Building cosine similarity matrix for [24096, 24144)...\n",
      "[ 899 ] Building cosine similarity matrix for [32144, 32192)...\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (10000, 32195)\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")\n",
    "cbf = ContentBasedFiltering()\n",
    "cbf.fit(urm,\n",
    "        list(tg_playlist),\n",
    "        list(tg_tracks),\n",
    "        dataset, \n",
    "        topK_tag=55)\n",
    "#recs = cbf.predict()\n",
    "#ev.evaluate_fold(recs)\n",
    "S_cbf_full = cbf.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 workers...\n",
      "[ 901 ] Building cosine similarity matrix for [0, 1000)...\n",
      "[ 902 ] Building cosine similarity matrix for [8048, 9048)...\n",
      "[ 903 ] Building cosine similarity matrix for [16096, 17096)...\n",
      "[ 904 ] Building cosine similarity matrix for [24144, 25144)...\n",
      "[ 901 ] Building cosine similarity matrix for [1000, 2000)...\n",
      "[ 902 ] Building cosine similarity matrix for [9048, 10048)...\n",
      "[ 903 ] Building cosine similarity matrix for [17096, 18096)...\n",
      "[ 904 ] Building cosine similarity matrix for [25144, 26144)...\n",
      "[ 901 ] Building cosine similarity matrix for [2000, 3000)...\n",
      "[ 902 ] Building cosine similarity matrix for [10048, 11048)...\n",
      "[ 903 ] Building cosine similarity matrix for [18096, 19096)...\n",
      "[ 904 ] Building cosine similarity matrix for [26144, 27144)...\n",
      "[ 901 ] Building cosine similarity matrix for [3000, 4000)...\n",
      "[ 902 ] Building cosine similarity matrix for [11048, 12048)...\n",
      "[ 903 ] Building cosine similarity matrix for [19096, 20096)...\n",
      "[ 904 ] Building cosine similarity matrix for [27144, 28144)...\n",
      "[ 901 ] Building cosine similarity matrix for [4000, 5000)...\n",
      "[ 902 ] Building cosine similarity matrix for [12048, 13048)...\n",
      "[ 903 ] Building cosine similarity matrix for [20096, 21096)...\n",
      "[ 904 ] Building cosine similarity matrix for [28144, 29144)...\n",
      "[ 901 ] Building cosine similarity matrix for [5000, 6000)...\n",
      "[ 902 ] Building cosine similarity matrix for [13048, 14048)...\n",
      "[ 903 ] Building cosine similarity matrix for [21096, 22096)...\n",
      "[ 904 ] Building cosine similarity matrix for [29144, 30144)...\n",
      "[ 901 ] Building cosine similarity matrix for [6000, 7000)...\n",
      "[ 902 ] Building cosine similarity matrix for [14048, 15048)...\n",
      "[ 903 ] Building cosine similarity matrix for [22096, 23096)...\n",
      "[ 904 ] Building cosine similarity matrix for [30144, 31144)...\n",
      "[ 901 ] Building cosine similarity matrix for [7000, 8000)...\n",
      "[ 902 ] Building cosine similarity matrix for [15048, 16048)...\n",
      "[ 903 ] Building cosine similarity matrix for [23096, 24096)...\n",
      "[ 904 ] Building cosine similarity matrix for [31144, 32144)...\n",
      "[ 901 ] Building cosine similarity matrix for [8000, 8048)...\n",
      "[ 902 ] Building cosine similarity matrix for [16048, 16096)...\n",
      "[ 901 ] Building cosine similarity matrix for [32192, 32195)...\n",
      "[ 903 ] Building cosine similarity matrix for [24096, 24144)...\n",
      "[ 904 ] Building cosine similarity matrix for [32144, 32192)...\n",
      "S done\n",
      "Similarity matrix ready!\n"
     ]
    }
   ],
   "source": [
    "dataset.set_playlist_attr_weights(1, 1, 1, 0, 0)\n",
    "ucm = dataset.build_ucm()\n",
    "S_user = ubs(urm, ucm, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 workers...\n",
      "[ 914 ] Building cosine similarity matrix for [0, 1000)...\n",
      "[ 915 ] Building cosine similarity matrix for [8048, 9048)...\n",
      "[ 916 ] Building cosine similarity matrix for [16096, 17096)...\n",
      "[ 917 ] Building cosine similarity matrix for [24144, 25144)...\n",
      "[ 914 ] Building cosine similarity matrix for [1000, 2000)...\n",
      "[ 915 ] Building cosine similarity matrix for [9048, 10048)...\n",
      "[ 914 ] Building cosine similarity matrix for [2000, 3000)...\n",
      "[ 915 ] Building cosine similarity matrix for [10048, 11048)...\n",
      "[ 916 ] Building cosine similarity matrix for [17096, 18096)...\n",
      "[ 914 ] Building cosine similarity matrix for [3000, 4000)...\n",
      "[ 915 ] Building cosine similarity matrix for [11048, 12048)...\n",
      "[ 916 ] Building cosine similarity matrix for [18096, 19096)...\n",
      "[ 917 ] Building cosine similarity matrix for [25144, 26144)...\n",
      "[ 914 ] Building cosine similarity matrix for [4000, 5000)...\n",
      "[ 915 ] Building cosine similarity matrix for [12048, 13048)...\n",
      "[ 917 ] Building cosine similarity matrix for [26144, 27144)...\n",
      "[ 914 ] Building cosine similarity matrix for [5000, 6000)...\n",
      "[ 916 ] Building cosine similarity matrix for [19096, 20096)...\n",
      "[ 915 ] Building cosine similarity matrix for [13048, 14048)...\n",
      "[ 914 ] Building cosine similarity matrix for [6000, 7000)...\n",
      "[ 917 ] Building cosine similarity matrix for [27144, 28144)...\n",
      "[ 916 ] Building cosine similarity matrix for [20096, 21096)...\n",
      "[ 914 ] Building cosine similarity matrix for [7000, 8000)...\n",
      "[ 915 ] Building cosine similarity matrix for [14048, 15048)...\n",
      "[ 917 ] Building cosine similarity matrix for [28144, 29144)...\n",
      "[ 916 ] Building cosine similarity matrix for [21096, 22096)...\n",
      "[ 914 ] Building cosine similarity matrix for [8000, 8048)...\n",
      "[ 915 ] Building cosine similarity matrix for [15048, 16048)...\n",
      "[ 917 ] Building cosine similarity matrix for [29144, 30144)...\n",
      "[ 916 ] Building cosine similarity matrix for [22096, 23096)...\n",
      "[ 916 ] Building cosine similarity matrix for [23096, 24096)...\n",
      "[ 917 ] Building cosine similarity matrix for [30144, 31144)...\n",
      "[ 915 ] Building cosine similarity matrix for [16048, 16096)...\n",
      "[ 914 ] Building cosine similarity matrix for [32192, 32195)...\n",
      "[ 916 ] Building cosine similarity matrix for [24096, 24144)...\n",
      "[ 917 ] Building cosine similarity matrix for [31144, 32144)...\n",
      "[ 917 ] Building cosine similarity matrix for [32144, 32192)...\n",
      "Similarity matrix ready!\n"
     ]
    }
   ],
   "source": [
    "S_urm = ibs(urm, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 919 ] Building cosine similarity matrix for [0, 1000)...\n",
      "Running 4 workers...\n",
      "[ 920 ] Building cosine similarity matrix for [8048, 9048)...\n",
      "[ 921 ] Building cosine similarity matrix for [16096, 17096)...\n",
      "[ 922 ] Building cosine similarity matrix for [24144, 25144)...\n",
      "[ 919 ] Building cosine similarity matrix for [1000, 2000)...\n",
      "[ 920 ] Building cosine similarity matrix for [9048, 10048)...\n",
      "[ 921 ] Building cosine similarity matrix for [17096, 18096)...\n",
      "[ 922 ] Building cosine similarity matrix for [25144, 26144)...\n",
      "[ 919 ] Building cosine similarity matrix for [2000, 3000)...\n",
      "[ 921 ] Building cosine similarity matrix for [18096, 19096)...\n",
      "[ 920 ] Building cosine similarity matrix for [10048, 11048)...\n",
      "[ 922 ] Building cosine similarity matrix for [26144, 27144)...\n",
      "[ 919 ] Building cosine similarity matrix for [3000, 4000)...\n",
      "[ 921 ] Building cosine similarity matrix for [19096, 20096)...\n",
      "[ 920 ] Building cosine similarity matrix for [11048, 12048)...\n",
      "[ 922 ] Building cosine similarity matrix for [27144, 28144)...\n",
      "[ 921 ] Building cosine similarity matrix for [20096, 21096)...\n",
      "[ 919 ] Building cosine similarity matrix for [4000, 5000)...\n",
      "[ 920 ] Building cosine similarity matrix for [12048, 13048)...\n",
      "[ 922 ] Building cosine similarity matrix for [28144, 29144)...\n",
      "[ 921 ] Building cosine similarity matrix for [21096, 22096)...\n",
      "[ 919 ] Building cosine similarity matrix for [5000, 6000)...\n",
      "[ 920 ] Building cosine similarity matrix for [13048, 14048)...\n",
      "[ 922 ] Building cosine similarity matrix for [29144, 30144)...\n",
      "[ 919 ] Building cosine similarity matrix for [6000, 7000)...\n",
      "[ 921 ] Building cosine similarity matrix for [22096, 23096)...\n",
      "[ 920 ] Building cosine similarity matrix for [14048, 15048)...\n",
      "[ 922 ] Building cosine similarity matrix for [30144, 31144)...\n",
      "[ 921 ] Building cosine similarity matrix for [23096, 24096)...\n",
      "[ 919 ] Building cosine similarity matrix for [7000, 8000)...\n",
      "[ 920 ] Building cosine similarity matrix for [15048, 16048)...\n",
      "[ 922 ] Building cosine similarity matrix for [31144, 32144)...\n",
      "[ 921 ] Building cosine similarity matrix for [24096, 24144)...\n",
      "[ 919 ] Building cosine similarity matrix for [8000, 8048)...\n",
      "[ 922 ] Building cosine similarity matrix for [32144, 32192)...\n",
      "[ 921 ] Building cosine similarity matrix for [32192, 32195)...\n",
      "[ 920 ] Building cosine similarity matrix for [16048, 16096)...\n",
      "S done\n",
      "Similarity matrix ready!\n"
     ]
    }
   ],
   "source": [
    "dataset.set_track_attr_weights_2(1.5, 1.6, 0, 0, 0.0,\n",
    "                                 1.0, 0, 0.0, 0.0)\n",
    "S_icm = icm_sim(dataset.build_icm(), dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (10000, 32195)\n"
     ]
    }
   ],
   "source": [
    "# Best params 0.53119031862654198, 0.8622528471283929, 0.449568357270693, 0.84725181341512967]\n",
    "# [0.24995989924853496, 0.35681721890423695, 0.12389358733625891, 0.78110404084094665]\n",
    "# weights = [0.53, 0.86, 0.45, 0.85]\n",
    "S = S_icm * 0.24995989924853496 + S_urm * 0.35681721890423695 + S_user * 0.12389358733625891 + S_cbf_full * 0.78110404084094665\n",
    "print(\"Similarity matrix ready!\")\n",
    "\n",
    "s_norm = S.sum(axis=0)\n",
    "s_norm[s_norm==0] = 1\n",
    "# Normalize S\n",
    "S = S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "\n",
    "# Keep only the target playlists in the URM\n",
    "urm_cleaned = urm[[dataset.get_playlist_index_from_id(x)\n",
    "                   for x in tg_playlist]]\n",
    "\n",
    "# Compute ratings\n",
    "R_hat = urm_cleaned.dot(S.tocsc()).tocsr()\n",
    "print(\"R_hat done\")\n",
    "\n",
    "# Remove the entries in R_hat that are already present in the URM\n",
    "urm_cleaned = urm_cleaned[:, [dataset.get_track_index_from_id(x)\n",
    "                              for x in tg_tracks]]\n",
    "R_hat[urm_cleaned.nonzero()] = 0\n",
    "R_hat.eliminate_zeros()\n",
    "\n",
    "print(\"Shape of final matrix: \", R_hat.shape)\n",
    "recs = predict(R_hat, list(tg_playlist), list(tg_tracks))\n",
    "#ev.evaluate_fold(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(R_hat, pl_id_list, tr_id_list, at=5):\n",
    "        \"\"\"\n",
    "        returns a dictionary of\n",
    "        'pl_id': ['tr_1', 'tr_at'] for each playlist in target playlist\n",
    "        \"\"\"\n",
    "        recs = {}\n",
    "        for i in range(0, R_hat.shape[0]):\n",
    "            pl_id = pl_id_list[i]\n",
    "            pl_row = R_hat.data[R_hat.indptr[i]:\n",
    "                                     R_hat.indptr[i + 1]]\n",
    "            # get top 5 indeces. argsort, flip and get first at-1 items\n",
    "            sorted_row_idx = np.flip(pl_row.argsort(), axis=0)[0:at]\n",
    "            track_cols = [R_hat.indices[R_hat.indptr[i] + x]\n",
    "                          for x in sorted_row_idx]\n",
    "            tracks_ids = [tr_id_list[x] for x in track_cols]\n",
    "            recs[pl_id] = tracks_ids\n",
    "        return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_ensemble.csv', mode='w', newline='') as out:\n",
    "    fieldnames = ['playlist_id', 'track_ids']\n",
    "    writer = csv.DictWriter(out, fieldnames=fieldnames, delimiter=',')\n",
    "    writer.writeheader()\n",
    "    for k in tg_playlist:\n",
    "        track_ids = ''\n",
    "        for r in recs[k]:\n",
    "            track_ids = track_ids + r + ' '\n",
    "        writer.writerow({'playlist_id': k,\n",
    "                         'track_ids': track_ids[:-1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixS(params):\n",
    "    global S_icm, S_user, S_urm, S_cbf_full, urm, tg_playlist, evaluator\n",
    "    print(params)\n",
    "\n",
    "    S = S_icm * params[0] + S_urm * params[1] + S_user * params[2] + S_cbf_full * params[3]\n",
    "    print(\"Similarity matrix ready!\")\n",
    "\n",
    "    s_norm = S.sum(axis=0)\n",
    "    s_norm[s_norm==0] = 1\n",
    "    # Normalize S\n",
    "    S= S.multiply(csr_matrix(np.reciprocal(s_norm)))\n",
    "    print(\"Similarity matrix ready!\")\n",
    "\n",
    "    # Keep only the target playlists in the URM\n",
    "    urm_cleaned = urm[[dataset.get_playlist_index_from_id(x)\n",
    "                       for x in tg_playlist]]\n",
    "\n",
    "    # Compute ratings\n",
    "    R_hat = urm_cleaned.dot(S.tocsc()).tocsr()\n",
    "    print(\"R_hat done\")\n",
    "\n",
    "    # Remove the entries in R_hat that are already present in the URM\n",
    "    urm_cleaned = urm_cleaned[:, [dataset.get_track_index_from_id(x)\n",
    "                                  for x in tg_tracks]]\n",
    "    R_hat[urm_cleaned.nonzero()] = 0\n",
    "    R_hat.eliminate_zeros()\n",
    "\n",
    "    print(\"Shape of final matrix: \", R_hat.shape)\n",
    "    recs = predict(R_hat, list(tg_playlist), list(tg_tracks))\n",
    "    map_at_five = ev.evaluate_fold(recs)\n",
    "    return -map_at_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at provided point.\n",
      "[1, 0, 0, 0]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.09656894679696001\n",
      "[0, 1, 0, 0]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.08265773917239722\n",
      "[0, 0, 1, 0]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.0711895282905054\n",
      "[0, 0, 0, 1]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10914706237181827\n",
      "[0.531190318626542, 0.8622528471283929, 0.449568357270693, 0.8472518134151297]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11102002654119943\n",
      "Iteration No: 1 ended. Evaluation done at provided point.\n",
      "Time taken: 147.7587\n",
      "Function value obtained: -0.1110\n",
      "Current minimum: -0.1110\n",
      "Iteration No: 2 started. Evaluating function at provided point.\n",
      "[0.8912292816900047, 0.71915021438407289, 0.85299895501253731, 0.80610524819676732]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11077150440342658\n",
      "Iteration No: 2 ended. Evaluation done at provided point.\n",
      "Time taken: 30.1963\n",
      "Function value obtained: -0.1108\n",
      "Current minimum: -0.1110\n",
      "Iteration No: 3 started. Evaluating function at provided point.\n",
      "[0.50996374529498867, 0.23255643964307088, 0.70555118853191723, 0.97681735780081314]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11118952829050568\n",
      "Iteration No: 3 ended. Evaluation done at provided point.\n",
      "Time taken: 29.7036\n",
      "Function value obtained: -0.1112\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 4 started. Evaluating function at provided point.\n",
      "[0.50812167900045235, 0.6121135944405075, 0.5418259569556293, 0.33107123530332189]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.1102141392206542\n",
      "Iteration No: 4 ended. Evaluation done at provided point.\n",
      "Time taken: 30.1975\n",
      "Function value obtained: -0.1102\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 5 started. Evaluating function at provided point.\n",
      "[0.97239903046753307, 0.55656604314016389, 0.12009980704033899, 0.41225697571338349]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10769332850766082\n",
      "Iteration No: 5 ended. Evaluation done at provided point.\n",
      "Time taken: 30.4555\n",
      "Function value obtained: -0.1077\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.73328772555138311, 0.95142531093324278, 0.0079824166238972056, 0.6358315162567536]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11014235734105465\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 29.9094\n",
      "Function value obtained: -0.1101\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.77437981386155508, 0.14868469099486661, 0.94476068969418447, 0.53171627391505683]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10945047653516726\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 30.1244\n",
      "Function value obtained: -0.1095\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.9862905340261362, 0.94317430740203934, 0.0021095530004219269, 0.17380578072410127]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10810652672216219\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 30.5617\n",
      "Function value obtained: -0.1081\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.25288375392117063, 0.5183213385383284, 0.5254392867854476, 0.71995999461826821]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11111774641090646\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 30.6155\n",
      "Function value obtained: -0.1111\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.75984767645638174, 0.0084247955440868178, 0.025750169362022242, 0.0047159378629084711]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.09836892266859709\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 30.2924\n",
      "Function value obtained: -0.0984\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.57489623977860049, 0.049827124413522342, 0.69620829148603669, 0.1479149883624982]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10762154662806146\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 30.3088\n",
      "Function value obtained: -0.1076\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.77712362513386291, 0.086409942352605698, 0.38378177914643175, 0.64414105640861741]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10769574134394992\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 30.2691\n",
      "Function value obtained: -0.1077\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.62701694729339874, 0.64153020629084179, 0.14753452014988014, 0.48584139796155013]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11016286644951152\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 30.7057\n",
      "Function value obtained: -0.1102\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.17713786582671556, 0.25194131112019574, 0.10628446559130802, 0.95167724117110808]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11092471950778193\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 33.6751\n",
      "Function value obtained: -0.1109\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.75901733049556352, 0.34635532661560492, 0.52436974645849055, 0.97152629340274799]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.1102702376643746\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 30.3470\n",
      "Function value obtained: -0.1103\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.98788515071417282, 0.48793005509811738, 0.88081725936100053, 0.19417188858981499]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10946314392568474\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 30.6717\n",
      "Function value obtained: -0.1095\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.53013825531594427, 0.89703023425535311, 0.93625830413158273, 0.59459116557449454]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11031427192665015\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 29.8000\n",
      "Function value obtained: -0.1103\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.23342451622466559, 0.54674481574467526, 0.96822048481936052, 0.39673416936875994]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10834539751477924\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 29.7852\n",
      "Function value obtained: -0.1083\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.05069751555076242, 0.64889202354619213, 0.084590967317046198, 0.49890269614300187]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10596272167933436\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 30.1245\n",
      "Function value obtained: -0.1060\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.76749212652021015, 0.8955252043306634, 0.10347024766782634, 0.85988554195314881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.1100307636626856\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 30.0728\n",
      "Function value obtained: -0.1100\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 21 started. Evaluating function at random point.\n",
      "[0.20960644552278335, 0.98174549019420865, 0.34502655875138782, 0.50129713374349893]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10766859693569845\n",
      "Iteration No: 21 ended. Evaluation done at random point.\n",
      "Time taken: 32.1869\n",
      "Function value obtained: -0.1077\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 22 started. Evaluating function at random point.\n",
      "[0.2014585341804665, 0.48495266638890444, 0.95904980481268454, 0.09675223558044535]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10442031608155433\n",
      "Iteration No: 22 ended. Evaluation done at random point.\n",
      "Time taken: 30.1288\n",
      "Function value obtained: -0.1044\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 23 started. Evaluating function at random point.\n",
      "[0.097299012808137159, 0.15074895637344235, 0.88413778733556747, 0.13083462497738033]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.09979913137893617\n",
      "Iteration No: 23 ended. Evaluation done at random point.\n",
      "Time taken: 30.3084\n",
      "Function value obtained: -0.0998\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 24 started. Evaluating function at random point.\n",
      "[0.91800468185213213, 0.85064841001134273, 0.0095950942289584357, 0.52147990963662172]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10907528049221875\n",
      "Iteration No: 24 ended. Evaluation done at random point.\n",
      "Time taken: 30.3173\n",
      "Function value obtained: -0.1091\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 25 started. Evaluating function at random point.\n",
      "[0.58885986996712314, 0.6354771465536323, 0.71196620499717034, 0.19410499286143296]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10995717215586932\n",
      "Iteration No: 25 ended. Evaluation done at random point.\n",
      "Time taken: 29.8460\n",
      "Function value obtained: -0.1100\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 26 started. Evaluating function at random point.\n",
      "[0.37035930158302904, 0.037153585306416444, 0.42374208963268967, 0.043219228348659218]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10677886355410789\n",
      "Iteration No: 26 ended. Evaluation done at random point.\n",
      "Time taken: 29.8845\n",
      "Function value obtained: -0.1068\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 27 started. Evaluating function at random point.\n",
      "[0.47070646308829556, 0.10201693439178186, 0.53132364773482199, 0.84265918867207068]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11091627458077004\n",
      "Iteration No: 27 ended. Evaluation done at random point.\n",
      "Time taken: 29.9453\n",
      "Function value obtained: -0.1109\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 28 started. Evaluating function at random point.\n",
      "[0.81690483344433185, 0.55852501496179996, 0.94201754481592126, 0.36101448600382197]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11003136687175803\n",
      "Iteration No: 28 ended. Evaluation done at random point.\n",
      "Time taken: 30.3352\n",
      "Function value obtained: -0.1100\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 29 started. Evaluating function at random point.\n",
      "[0.74808362388133087, 0.0039602153978315355, 0.65859250380464363, 0.3863075418017704]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10707322958137314\n",
      "Iteration No: 29 ended. Evaluation done at random point.\n",
      "Time taken: 30.4282\n",
      "Function value obtained: -0.1071\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 30 started. Evaluating function at random point.\n",
      "[0.038404510910398766, 0.92511835841375445, 0.23480361220357787, 0.99663509339725376]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10658221739654995\n",
      "Iteration No: 30 ended. Evaluation done at random point.\n",
      "Time taken: 29.9853\n",
      "Function value obtained: -0.1066\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 31 started. Evaluating function at random point.\n",
      "[0.59683809239374974, 0.10957504816871302, 0.18925375738273026, 0.77924210961744245]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10866208227771773\n",
      "Iteration No: 31 ended. Evaluation done at random point.\n",
      "Time taken: 29.8452\n",
      "Function value obtained: -0.1087\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 32 started. Evaluating function at random point.\n",
      "[0.65797340941323113, 0.19255675756424956, 0.48759517645930361, 0.1534685662932265]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.1077078055253951\n",
      "Iteration No: 32 ended. Evaluation done at random point.\n",
      "Time taken: 30.1216\n",
      "Function value obtained: -0.1077\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 33 started. Evaluating function at random point.\n",
      "[0.39066944346324495, 0.18443155338742293, 0.88186088849378497, 0.43835065623755831]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11021896489323242\n",
      "Iteration No: 33 ended. Evaluation done at random point.\n",
      "Time taken: 29.9043\n",
      "Function value obtained: -0.1102\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 34 started. Evaluating function at random point.\n",
      "[0.15603653712920465, 0.16663708682337888, 0.91511418621228313, 0.18750541781050017]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10509711666063498\n",
      "Iteration No: 34 ended. Evaluation done at random point.\n",
      "Time taken: 30.3824\n",
      "Function value obtained: -0.1051\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 35 started. Evaluating function at random point.\n",
      "[0.22992681174884561, 0.40427605251423682, 0.31018947182161621, 0.1372243894651978]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10934732778381022\n",
      "Iteration No: 35 ended. Evaluation done at random point.\n",
      "Time taken: 30.2138\n",
      "Function value obtained: -0.1093\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 36 started. Evaluating function at random point.\n",
      "[0.83691260189852679, 0.066630321374171034, 0.16623970098432797, 0.72591840866437896]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10591325853540871\n",
      "Iteration No: 36 ended. Evaluation done at random point.\n",
      "Time taken: 29.7943\n",
      "Function value obtained: -0.1059\n",
      "Current minimum: -0.1112\n",
      "Iteration No: 37 started. Evaluating function at random point.\n",
      "[0.24995989924853496, 0.35681721890423695, 0.12389358733625891, 0.78110404084094665]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.1114229702014721\n",
      "Iteration No: 37 ended. Evaluation done at random point.\n",
      "Time taken: 30.0299\n",
      "Function value obtained: -0.1114\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 38 started. Evaluating function at random point.\n",
      "[0.76888549955810104, 0.040754673711301266, 0.25730583391197231, 0.87309598822262846]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10717155266015226\n",
      "Iteration No: 38 ended. Evaluation done at random point.\n",
      "Time taken: 30.1173\n",
      "Function value obtained: -0.1072\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 39 started. Evaluating function at random point.\n",
      "[0.92102996249883007, 0.87387981661454417, 0.09803240814964545, 0.89099175722272872]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10993063095668955\n",
      "Iteration No: 39 ended. Evaluation done at random point.\n",
      "Time taken: 30.2162\n",
      "Function value obtained: -0.1099\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 40 started. Evaluating function at random point.\n",
      "[0.61922671184784595, 0.14996229377710227, 0.4765302302582981, 0.76489291214473232]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10988056460369192\n",
      "Iteration No: 40 ended. Evaluation done at random point.\n",
      "Time taken: 29.8054\n",
      "Function value obtained: -0.1099\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 41 started. Evaluating function at random point.\n",
      "[0.73307302615189085, 0.80614410332001873, 0.43994953292918149, 0.97830718622784762]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11102967788635568\n",
      "Iteration No: 41 ended. Evaluation done at random point.\n",
      "Time taken: 30.0286\n",
      "Function value obtained: -0.1110\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 42 started. Evaluating function at random point.\n",
      "[0.18019860611998875, 0.91618732181741314, 0.60513908377904835, 0.66025155227094046]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10750452406804233\n",
      "Iteration No: 42 ended. Evaluation done at random point.\n",
      "Time taken: 29.9681\n",
      "Function value obtained: -0.1075\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 43 started. Evaluating function at random point.\n",
      "[0.22318695419012585, 0.40304985895062784, 0.23886089447232878, 0.90097652154658503]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11109723730244941\n",
      "Iteration No: 43 ended. Evaluation done at random point.\n",
      "Time taken: 34.8357\n",
      "Function value obtained: -0.1111\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 44 started. Evaluating function at random point.\n",
      "[0.05777280844955103, 0.25385222773190846, 0.22475905222470444, 0.83058608188019378]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11137049101218523\n",
      "Iteration No: 44 ended. Evaluation done at random point.\n",
      "Time taken: 30.7125\n",
      "Function value obtained: -0.1114\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 45 started. Evaluating function at random point.\n",
      "[0.36407509944698097, 0.98279131682375209, 0.55404839696007302, 0.97361316941047116]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11038726022439417\n",
      "Iteration No: 45 ended. Evaluation done at random point.\n",
      "Time taken: 29.8466\n",
      "Function value obtained: -0.1104\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 46 started. Evaluating function at random point.\n",
      "[0.3799205886894198, 0.19480953313057864, 0.30808142906010499, 0.2312827026801772]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.109887803112559\n",
      "Iteration No: 46 ended. Evaluation done at random point.\n",
      "Time taken: 29.8300\n",
      "Function value obtained: -0.1099\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 47 started. Evaluating function at random point.\n",
      "[0.48575050048993929, 0.81512510513127978, 0.050815360917704458, 0.65202051639621172]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.1108167450838465\n",
      "Iteration No: 47 ended. Evaluation done at random point.\n",
      "Time taken: 30.0391\n",
      "Function value obtained: -0.1108\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 48 started. Evaluating function at random point.\n",
      "[0.020236104634177691, 0.45984638606376926, 0.92936335053303842, 0.40865722771813084]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10064181445288951\n",
      "Iteration No: 48 ended. Evaluation done at random point.\n",
      "Time taken: 31.0130\n",
      "Function value obtained: -0.1006\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 49 started. Evaluating function at random point.\n",
      "[0.39407663216731004, 0.64160568206607815, 0.42532679251816974, 0.35623420402027112]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11006152732537142\n",
      "Iteration No: 49 ended. Evaluation done at random point.\n",
      "Time taken: 30.5905\n",
      "Function value obtained: -0.1101\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 50 started. Evaluating function at random point.\n",
      "[0.052183750391651809, 0.41411378459765491, 0.78068842959855922, 0.22016788086302047]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.09997587163710955\n",
      "Iteration No: 50 ended. Evaluation done at random point.\n",
      "Time taken: 30.1602\n",
      "Function value obtained: -0.1000\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 51 started. Evaluating function at random point.\n",
      "[0.51676706913031878, 0.16382229724630973, 0.72723776952573438, 0.51308128800921249]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11045843889492118\n",
      "Iteration No: 51 ended. Evaluation done at random point.\n",
      "Time taken: 30.8883\n",
      "Function value obtained: -0.1105\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 52 started. Evaluating function at random point.\n",
      "[0.002664733125895991, 0.094216629581925365, 0.51170156284508816, 0.9609084724599023]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.11072324767764538\n",
      "Iteration No: 52 ended. Evaluation done at random point.\n",
      "Time taken: 30.3303\n",
      "Function value obtained: -0.1107\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 53 started. Evaluating function at random point.\n",
      "[0.018724888303033097, 0.010311560503294516, 0.469129683488266, 0.3759974265573981]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10784352756665494\n",
      "Iteration No: 53 ended. Evaluation done at random point.\n",
      "Time taken: 31.1195\n",
      "Function value obtained: -0.1078\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 54 started. Evaluating function at random point.\n",
      "[0.0071188109663642436, 0.72591593779027408, 0.45782798073568765, 0.092225995405317743]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.09057546145494051\n",
      "Iteration No: 54 ended. Evaluation done at random point.\n",
      "Time taken: 31.8875\n",
      "Function value obtained: -0.0906\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 55 started. Evaluating function at random point.\n",
      "[0.55035068429723211, 0.62947192508973404, 0.89795230987977881, 0.034539642658399934]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10920858969718934\n",
      "Iteration No: 55 ended. Evaluation done at random point.\n",
      "Time taken: 31.8743\n",
      "Function value obtained: -0.1092\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "[0.4392079729381777, 0.93774844908066257, 0.97854972448334132, 0.008870197886219235]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n",
      "MAP@5: 0.10746652189648966\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.8107\n",
      "Function value obtained: -0.1075\n",
      "Current minimum: -0.1114\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "[0.24694831876175977, 0.77984633745769705, 0.87317496401709094, 0.0015067151501635405]\n",
      "Similarity matrix ready!\n",
      "Similarity matrix ready!\n",
      "R_hat done\n",
      "Shape of final matrix:  (5526, 20730)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-781e77c1604c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.53119031862654198\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8622528471283929\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.449568357270693\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.84725181341512967\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mx0s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Maximimum p@k found: {:6.5f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimal parameters:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/RS/lib/python3.6/site-packages/skopt/optimizer/forest.py\u001b[0m in \u001b[0;36mforest_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    160\u001b[0m                          \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                          \u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                          callback=callback, acq_optimizer=\"sampling\")\n\u001b[0m",
      "\u001b[0;32m~/Development/RS/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# no need to fit a model on the last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_calls\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-0116847ea486>\u001b[0m in \u001b[0;36mmixS\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of final matrix: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtg_playlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtg_tracks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmap_at_five\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmap_at_five\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/RS/recsys_challenge_2017/src/utils/evaluator.py\u001b[0m in \u001b[0;36mevaluate_fold\u001b[0;34m(self, recommendation, at)\u001b[0m\n\u001b[1;32m    143\u001b[0m                         \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0map\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mtr_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tracks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_fold_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: Track not in target tracks!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mitem_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skopt import forest_minimize\n",
    "from skopt.space import Integer, Real\n",
    "space = [Real(0.0, 1.0),  # ICM\n",
    "         Real(0.0, 1.0),  # URM\n",
    "         Real(0.0, 1.0),  # USER\n",
    "         Real(0.0, 1.0),  # CBF_FULL\n",
    "             ]\n",
    "x0 = [1, 0, 0, 0]\n",
    "x1 = [0, 1, 0, 0]\n",
    "x2 = [0, 0, 1, 0]\n",
    "x3 = [0, 0, 0, 1]\n",
    "x4 = [0.53119031862654198, 0.8622528471283929, 0.449568357270693, 0.84725181341512967]\n",
    "x0s = [x0, x1, x2, x3, x4]\n",
    "res = forest_minimize(mixS, space, x0=x0s, verbose=True, n_random_starts=50, n_calls=1000, n_jobs=-1)\n",
    "print('Maximimum p@k found: {:6.5f}'.format(-res.fun))\n",
    "print('Optimal parameters:')\n",
    "params = ['ICM', 'URM', 'USER', 'FULL']\n",
    "for (p, x_) in zip(params, res.x):\n",
    "    print('{}: {}'.format(p, x_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
